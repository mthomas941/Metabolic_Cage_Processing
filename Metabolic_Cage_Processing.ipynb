{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "File_1 Name:  Chow Cohort- Ghrelin pt. 1.csv\n",
      "File_2 Name:  Chow Cohort- Ghrelin pt. 2.csv\n"
     ]
    }
   ],
   "source": [
    "#Read in files and put into dataframe\n",
    "file_1 = pd.read_csv(str(input('File_1 Name: ')), skiprows=12, encoding='latin1') #Chow Cohort- Ghrelin pt. 1.csv\n",
    "file_2 = pd.read_csv(str(input('File_2 Name: ')), skiprows=12, encoding='latin1') #Chow Cohort- Ghrelin pt. 2.csv\n",
    "\n",
    "#Store and drop first row containing measurement units\n",
    "measurement_units_dict = dict(zip(\n",
    "    file_1.drop(['Date Time', 'Animal No.', 'Box', 'Unnamed: 25'], axis=1).fillna('[RER]').columns, \n",
    "    file_1.drop(['Date Time', 'Animal No.', 'Box', 'Unnamed: 25'], axis=1).fillna('[RER]').iloc[0].values)\n",
    "                             )\n",
    "file_1 = file_1.drop(index=0)\n",
    "file_1.drop('Unnamed: 25', axis=1, inplace=True)\n",
    "file_1 = file_1.reset_index(drop=True)\n",
    "file_2 = file_2.drop(index=0)\n",
    "file_2.drop('Unnamed: 25', axis=1, inplace=True)\n",
    "file_2 = file_2.reset_index(drop=True)\n",
    "\n",
    "#Convert Date Time to datetime and other columns to numeric (RER won't convert if an animal is missing...will convert later)\n",
    "file_1 = file_1.apply(pd.to_numeric, errors='ignore')\n",
    "file_1['Date Time'] = file_1['Date Time'].apply(pd.to_datetime)\n",
    "\n",
    "file_2 = file_2.apply(pd.to_numeric, errors='ignore')\n",
    "file_2['Date Time'] = file_2['Date Time'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for date/hour/minute and then drop the earlier starting df rows until start hour is the same\n",
    "file_1['date'] = file_1['Date Time'].dt.date\n",
    "file_1['hour'] = file_1['Date Time'].dt.hour\n",
    "file_1['minute'] = file_1['Date Time'].dt.minute\n",
    "\n",
    "file_2['date'] = file_2['Date Time'].dt.date\n",
    "file_2['hour'] = file_2['Date Time'].dt.hour\n",
    "file_2['minute'] = file_2['Date Time'].dt.minute\n",
    "\n",
    "# Drop the first time point for each animal until the HOURS are equal\n",
    "time_start_file_1_hour = np.arange(0, len(file_1['hour']), (len(file_1['hour'])/8), dtype=int)\n",
    "time_start_file_2_hour = np.arange(0, len(file_2['hour']), (len(file_2['hour'])/8), dtype=int)\n",
    "\n",
    "while int(abs(file_2['hour'].iloc[0] - file_1['hour'].iloc[0])) != 0:\n",
    "    time_start_file_1_hour = np.arange(0, len(file_1['hour']), (len(file_1['hour'])/8))\n",
    "    time_start_file_2_hour = np.arange(0, len(file_2['hour']), (len(file_2['hour'])/8))\n",
    "    file_1 = file_1.drop(index=time_start_file_1_hour)\n",
    "    file_1 = file_1.reset_index(drop=True)\n",
    "        \n",
    "# Drop the first time point for each animal until the MINUTES are <30 min. apart (readings everfile_2 27)\n",
    "time_start_file_1_minute = np.arange(0, len(file_1['minute']), (len(file_1['minute'])/8), dtype=int)\n",
    "time_start_file_2_minute = np.arange(0, len(file_2['minute']), (len(file_2['minute'])/8), dtype=int)\n",
    "\n",
    "while int(abs(file_2['minute'].iloc[0] - file_1['minute'].iloc[0])) > 30:\n",
    "    time_start_file_1_minute = np.arange(0, len(file_1['minute']), (len(file_1['minute'])/8))\n",
    "    time_start_file_2_minute = np.arange(0, len(file_2['minute']), (len(file_2['minute'])/8))\n",
    "    file_1 = file_1.drop(index=time_start_file_1_minute)\n",
    "    file_1 = file_1.reset_index(drop=True)\n",
    "    \n",
    "# Reduces number of time points for each animal in longer df to match animal value_counts in shorter df\n",
    "time_matched_df = pd.DataFrame()\n",
    "if len(file_2) > len(file_1):\n",
    "    for i in file_2['Animal No.'].unique():\n",
    "        time_matched_df = time_matched_df.append(file_2[file_2['Animal No.'] == i].iloc[:np.int(len(file_1)/8)])\n",
    "        time_matched_df = time_matched_df.reset_index(drop=True)\n",
    "    file_2 = time_matched_df\n",
    "\n",
    "if len(file_2) < len(file_1):\n",
    "    for i in file_1['Animal No.'].unique():\n",
    "        time_matched_df = time_matched_df.append(file_1[file_1['Animal No.'] == i].iloc[:np.int(len(file_2)/8)])\n",
    "        time_matched_df = time_matched_df.reset_index(drop=True)\n",
    "    file_1 = time_matched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Date Time for both files the same and concat files into single dataframe\n",
    "file_2['Date Time'] = file_1['Date Time']\n",
    "df = pd.concat([file_1, file_2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Group_1 Animals (#, #, #...):  476, 481, 478, 487, 484, 491, 493\n",
      "Group_2 Animals (#, #, #...):  \n",
      "Group_1 Genotype:  cre\n",
      "Group_1 Genotype:  WT\n"
     ]
    }
   ],
   "source": [
    "#Create lists for Cre+ and WT animal numbers (or any two groups)\n",
    "group_1_list = input('Group_1 Animals (#, #, #...): ') #476, 481, 478, 487, 484, 491, 493\n",
    "group_1_list = [int(s) for s in group_1_list.split(', ') if s.isdigit()]\n",
    "\n",
    "group_2_list = input('Group_2 Animals (#, #, #...): ') #480, 477, 479, 482, 483, 489, 486\n",
    "group_2_list = [int(s) for s in group_2_list.split(', ') if s.isdigit()]\n",
    "\n",
    "#Create genotype identifiers for each group\n",
    "group_1_genotype = input('Group_1 Genotype: ') #cre\n",
    "group_2_genotype = input('Group_1 Genotype: ') #WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict of animal id's and genotye to map\n",
    "genotype_map_dict = dict(zip(group_1_list, [group_1_genotype for i in group_1_list]))\n",
    "genotype_map_dict.update(dict(zip(group_2_list, [group_2_genotype for i in group_2_list])))\n",
    "\n",
    "#Create new column for genotype and map each genotype according to animal id and corresponding group\n",
    "df['Genotype'] = df['Animal No.'].map(genotype_map_dict)\n",
    "\n",
    "#Drop any rows not containing an animal and convert RER to numeric\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "df['Date Time'] = df['Date Time'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unimportant columns and create .csv of combined, processed file\n",
    "df = df.drop(columns=['date', 'hour', 'minute'])\n",
    "combined_processed_file = str(input('Output File Name (*.csv): '))\n",
    "df.to_csv(path_or_buf=combined_processed_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
